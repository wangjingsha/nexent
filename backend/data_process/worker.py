"""
Celery worker script for data processing tasks

This script is used to start Celery workers for processing data
and forwarding to vector storage.

Enhanced with worker initialization signal design pattern.

Usage:
    # Start a worker that handles both queues
    python worker.py

    # Start a worker for processing only (high concurrency)
    QUEUES=process_q WORKER_CONCURRENCY=8 python worker.py

    # Start a worker for forwarding only (lower concurrency)
    QUEUES=forward_q WORKER_CONCURRENCY=2 python worker.py
"""

import os
import logging
import sys
import time
import traceback
import ray
from celery.signals import (
    worker_init,
    worker_ready, 
    worker_process_init,
    worker_shutting_down,
    task_prerun,
    task_postrun,
    task_failure
)

from .app import app
from .config import config
from .ray_config import init_ray_for_worker

# Global worker state for monitoring and debugging
worker_state = {
    'initialized': False,
    'ready': False,
    'start_time': None,
    'process_id': None,
    'tasks_completed': 0,
    'tasks_failed': 0,
    'environment_validated': False,
    'services_validated': False
}

logger = logging.getLogger("data_process.worker")

# ============================================================================
# WORKER INITIALIZATION SIGNALS
# ============================================================================

@worker_init.connect
def setup_worker_environment(**kwargs):
    """
    Call when initializing worker environment
    This is the earliest initialization step - environment variables and basic configuration
    """
    start_time = time.time()
    worker_state['start_time'] = start_time
    worker_state['process_id'] = os.getpid()
    
    logger.info("="*60)
    logger.info("üöÄ Celery Worker initialization started")
    logger.info(f"Process ID: {os.getpid()}")
    logger.info("="*60)
    
    try:
        # Initialize Ray - connect to existing cluster
        if not ray.is_initialized():
            logger.info("üîÆ Ray connecting to existing cluster...")
            
            # Get Ray address from environment
            ray_address = os.environ.get('RAY_ADDRESS', 'auto')
            
            try:
                # Use the new Ray configuration module if available
                if init_ray_for_worker:
                    if not init_ray_for_worker(ray_address):
                        raise ConnectionError("Failed to initialize Ray connection")
                else:
                    # Fallback to direct ray.init
                    ray.init(
                        address=ray_address, 
                        ignore_reinit_error=True,
                        _plasma_directory=config.ray_plasma_directory
                    )
                
                logger.info(f"‚úÖ Ray connected to cluster at {ray_address} successfully.")
                    
            except Exception as e:
                logger.error(f"‚ùå Failed to connect to Ray cluster: {str(e)}")
                logger.error("üí° Please make sure Ray cluster is started before workers!")
                logger.error("üí° You can start it via: python data_process_service.py")
                raise ConnectionError(f"Cannot connect to Ray cluster: {str(e)}")

        # Check environment variables
        logger.info("üîç Check sensitive variables")
        sensitive_vars = {
            'REDIS_URL': config.redis_url,
            'ELASTICSEARCH_SERVICE': config.elasticsearch_service
        }
        
        for var_name, var_value in sensitive_vars.items():
            if var_value:
                logger.debug(f"  ‚úÖ {var_name}: SET")
            else:
                logger.error(f"  ‚ùå {var_name}: NOT SET")
        
        worker_state['initialized'] = True
        elapsed = time.time() - start_time
        logger.debug(f"‚úÖ Worker environment initialized (time: {elapsed:.2f} s)")
        
    except Exception as e:
        logger.error(f"‚ùå Worker environment initialization failed: {str(e)}")
        logger.error(f"Error details: {traceback.format_exc()}")
        # Do not exit here, let Celery handle the error
        raise

@worker_process_init.connect
def setup_worker_process_resources(**kwargs):
    """
    Call when initializing each worker process
    Suitable for initializing process-specific resources (e.g. database connection pool)
    """
    process_id = os.getpid()
    logger.info(f"‚öôÔ∏è Initialize worker process {process_id}")
    
    try:
        # Initialize process-specific resources
        # e.g. database connection pool, cache client, etc.
        
        # Validate critical service connections
        logger.debug("üîç Validate service connections")
        validate_service_connections()
        worker_state['services_validated'] = True
        logger.debug("‚úÖ Service connections validated")
        
        # Initialize heavy objects like DataProcessCore
        logger.debug("‚öôÔ∏è Initialize data processing components")
        # Here we can pre-initialize global objects to avoid delays on the first task
        
        logger.debug(f"‚úÖ Worker process {process_id} initialized")
        
    except Exception as e:
        logger.error(f"‚ùå Worker process {process_id} initialization failed: {str(e)}")
        raise

@worker_ready.connect
def worker_ready_handler(**kwargs):
    """
    Call when worker is fully ready
    Suitable for registering services, starting monitoring, etc.
    """
    process_id = os.getpid()
    start_time = worker_state.get('start_time')
    total_startup_time = time.time() - start_time if start_time else 0
    
    worker_state['ready'] = True
    
    logger.debug("‚úÖ " + "="*50)
    logger.info("‚úÖ Celery Worker is fully ready!")
    logger.debug(f"Process ID: {process_id}")
    logger.debug(f"Total startup time: {total_startup_time:.2f} s")
    logger.debug("‚úÖ " + "="*50)
    
    # Display worker status summary
    logger.debug("üìä Worker status summary:")
    for key, value in worker_state.items():
        logger.debug(f"  {key}: {value}")
    
    # Register health check endpoints, start monitoring, etc.
    logger.debug("üîç Worker is ready to receive tasks")

@worker_shutting_down.connect
def worker_shutdown_handler(**kwargs):
    """Cleanup operations when the worker shuts down"""
    process_id = worker_state.get('process_id', os.getpid())
    uptime = time.time() - worker_state.get('start_time', time.time())
    
    logger.debug("üõë " + "="*50)
    logger.info("üõë Celery Worker is shutting down...")
    logger.debug(f"üõë Process ID: {process_id}")
    logger.debug(f"üõë Uptime: {uptime:.2f} s")
    logger.info(f"üõë Completed tasks: {worker_state.get('tasks_completed', 0)}")
    logger.info(f"üõë Failed tasks: {worker_state.get('tasks_failed', 0)}")
    logger.debug("üõë " + "="*50)

@task_prerun.connect
def task_prerun_handler(sender=None, task_id=None, task=None, args=None, kwargs=None, **kwds):
    """Handler before task execution"""
    logger.debug(f"üìã Task started: {task.name}[{task_id}]")

@task_postrun.connect
def task_postrun_handler(sender=None, task_id=None, task=None, args=None, kwargs=None, retval=None, state=None, **kwds):
    """Handler after task execution"""
    if state == 'SUCCESS':
        worker_state['tasks_completed'] += 1
        logger.debug(f"‚úÖ Task completed: {task.name}[{task_id}]")
    else:
        logger.debug(f"‚ö†Ô∏è Task ended: {task.name}[{task_id}] - State: {state}")

@task_failure.connect
def task_failure_handler(sender=None, task_id=None, exception=None, einfo=None, **kwds):
    """Handler when task fails"""
    worker_state['tasks_failed'] += 1
    logger.error(f"‚ùå Task failed: {sender.name}[{task_id}] - Exception: {str(exception)}")

# ============================================================================
# Service validation functions
# ============================================================================

def validate_service_connections() -> bool:
    """Validate critical service connections"""
    try:
        # Validate Redis connection
        logger.debug("üîç Validate Redis connection")
        validate_redis_connection()
        logger.debug("‚úÖ Redis connection is valid")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Service connection validation failed: {str(e)}")
        # Decide whether to raise an exception based on business requirements
        # Here we choose to log the error but not prevent the worker from starting
        return False

def validate_redis_connection() -> bool:
    """Validate Redis connection"""
    try:
        import redis
        redis_url = config.redis_url
        
        # Parse Redis URL and create connection
        redis_client = redis.from_url(redis_url, socket_timeout=5)
        
        # Test connection
        redis_client.ping()
        return True
        
    except ImportError:
        logger.warning("‚ö†Ô∏è Redis client not installed, skipping Redis connection validation")
        return False
    except Exception as e:
        logger.error(f"Redis connection failed: {str(e)}")
        raise

# ============================================================================
# Worker startup function
# ============================================================================

def start_worker():
    """Start Celery worker with appropriate settings"""
    
    # Get configuration parameters
    queues = os.environ.get('QUEUES', 'process_q,forward_q')
    worker_name = os.environ.get('WORKER_NAME', f'worker-{os.getpid()}')
    concurrency = int(os.environ.get('WORKER_CONCURRENCY', '4'))
    
    logger.info(f"Start Celery worker '{worker_name}' with queues: {queues}")
    logger.info(f"Worker concurrency: {concurrency}")
    
    # Display Celery configuration information
    logger.debug("üìã Celery configuration information:")
    logger.debug(f"  Broker URL: {app.conf.broker_url}")
    logger.debug(f"  Backend URL: {app.conf.result_backend}")
    logger.debug(f"  Task routes: {app.conf.task_routes}")
    logger.debug(f"  Task time limit: {config.celery_task_time_limit} s")
    logger.debug(f"  Worker prefetch multiplier: {config.celery_worker_prefetch_multiplier}")
    
    # Worker startup parameters
    worker_args = [
        'worker',
        '--loglevel=info',
        f'--queues={queues}',
        f'--hostname={worker_name}@%h',
        f'--concurrency={concurrency}',
        '--pool=threads',
        '--task-events'
    ]
    
    try:
        logger.info(f"‚öôÔ∏è  Start worker '{worker_name}'...")
        
        # Flush stdout to ensure immediate output
        sys.stdout.flush()
        
        # Start worker - signal handlers will be executed at appropriate times
        app.worker_main(worker_args)
        
    except KeyboardInterrupt:
        logger.info(f"üõë Worker '{worker_name}' was interrupted by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"‚ùå Error starting worker '{worker_name}': {str(e)}")
        logger.error(f"Error details: {traceback.format_exc()}")
        sys.exit(1)

if __name__ == '__main__':
    start_worker()
else:
    # Support importing this module and calling start_worker()
    logger.info("Worker module imported, will not start worker automatically")